# rag_from_pdf
This Jupyter Notebook demonstrates how to implement Retrieval-Augmented Generation (RAG) using a Large Language Model (LLM).
The pipeline extracts data from a PDF, summarises it, and enhances responses by retrieving relevant context before generating answers.

Included:

- Extract text, tables and images from PDFs
- Perform preprocessing & chunking
- Implement a vector-based retrieval system
- Use an LLM to generate context-aware responses
- Verification of the RAG pipeline for question-answering
